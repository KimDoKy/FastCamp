# 2017-2-1 (파이참 설정,웹 크롤링,모듈,패키지)
## 셸 설정, 파이참 단축키
`vi ~/.zshrc`
파이참 실행

`alias py="open -a /Applications/PyCharm\ CE.app/Contents/MacOS/pycharm"`
사용시 `py .`입력시 현재폴더를 기준으로 파이참 실행

`alt + F12` : 터미널 열기

가상환경 import
`usr/local/var/pyenv/versions/fc-python/bin/python`

`shift + cmd + -` : 그룹 닫기

`cmd + d` : iTerm 탭 추가
## 모듈
파일썬 파일은 각각 하나의 모듈로 취급됨.
실행, 함수의 정의, 단순변수의 모음 등 역활을 한다.
각각의 모듈들은 각각 클로저를 갖는다.

- module/shop.py

```python
 def buy_item():
     print('Buy item!')

 if __name__ == '__main__':
     buy_item()
```
- module/game.py

```python
 def play_game():
     print('Play game!')

 if __name__ == '__main__':
     play_game()
```
- module/lol.py

```python
 from func import game, shop

 print('= Turn on game =')
 game.play_game()
 shop.buy_item()
```
####  `__name__`변수
`ol.py`가 실행될 때, `game`과 `shop`가 `import`되는 순간 해당 코드가 실행되어 버리는 문제가 발생
이 때, 파이썬 인터프리터를 이용해 실행한 코드인지를 확인하여 단순히 `import`한 모듈의 경우 실행을 막는 방식을 사용할 수 있다.
모듈 이름은 모듈의 전역변수 `__name__`에서 확인 할 수 있다.  
`print(__name__)`

#### 네임스페이스 (Namespace)
각 모듈은 독립된 네임스페이스(이름공간)를 가진다. 메인으로 사용되고 있는 모듈이 아닌 import된 모듈의 경우, 해당 모듈의 네임스페이스를 사용해 모듈 내부의 데이터에 접근한다.
##### from을 사용해 모듈의 함수를 직접 import
`import 모듈명`의 경우, 모듈의 이름이 전역 네임스페이스에 등록되어 모듈명.함수로 사용가능
모듈명을 생략하고 모듈 내부의 함수를 쓰고 싶다면, `from 모듈명 import 함수명`으로 불러들일 수 있다.
##### `from 모듈명 * `을 사용해 모듈 내 모든 식별자 (변수, 함수) import

## 패키지
패키지는 모듈들을 모아 둔 특별한 **폴더**  
계층 구조를 가질 수 있으며, 모듈들을 해당 패키지에 모을 수 있는 역할을 한다.
패키지를 만들 때는 패키지로 사용할 폴더에 `__init__.py`파일을 넣어주면, 해당 폴더는 패키지로 취급된다.

```
├── func
│   ├── __init__.py
│   ├── game.py
│   └── shop.py
└── lol.py
```

## crawling

- crawl.py

```python
import parser
WEBTOON_ID = 651673
'''
네이버 웹툰 크롤러
환경 세팅
    1. alt + F12로 터미널 열기
    2. 터미널에서 pyenv version입력해서 가상환경이 적용된 터미널인지 확인
    3. pip 이용해서 BeautifulSoup4, requests설치
        pip install beautifulsoup4
        pip install requests
        pip install lxml
'''

result = parser.get_webtoon_episode_list(WEBTOON_ID)
# result = parser.get_episode_list_from_page(WEBTOON_ID)

f = open('webtoon.html', 'w')
f.write('<html><body>')
for item in result:
    f.write('''<div>
    <a href="http://comic.naver.com{href}">{title}</a>
    | <span>{created}</span>
</div>'''.format(
        href=item['link'],
        title=item['title'],
        created=item['created']
    ))
f.write('</body></html>')
f.close()
```
- parser > __init__.py

```python
from .page import *
```
- parser > communication.py

```python
import requests
from bs4 import BeautifulSoup


def get_soup_from_url(url, params=None):
    '''
    url과 parameter를 사용해서 해당 URL에 GET요청을 보낸 결과(HTML text)로
    BeautifulSoup객체를 생성해 반환
    :param url: GET요청을 보낼 URL string
    :param params: GET요청 매개변수 dict
    :return: BeautifulSoup object
    '''
    # requests.get요청을 보낸 결과값(response객체)을 r변수에 할당
    r = requests.get(url, params=params)
    # response객체에서 text메서드를 사용해 내용을 html_doc변수에 할당
    html_doc = r.text

    # BeautifulSoup객체를 생성, 인자는 html text
    soup = BeautifulSoup(html_doc, 'lxml')
    return soup
```
- parser > page.py

```python
from .communication import get_soup_from_url


def get_soup_from_naver_webtoon_by_page(webtoon_id, page=1):
    '''
    네이버웹툰의 만화 고유 ID(URL GET paramter중 titleId)와
    페이지넘버(URL GET paramter중 page)를 받아
    해당만화의 페이지(num)의 HTML을 BeautifulSoup객체로 반환
    :param webtoon_id: 네이버웹툰 고유 ID
    :param page: 주어지지 않을 경우 1페이지를 요청함
    :return: BeautifulSoup object
    '''
    # 네이버웹툰 사이트 주소
    url = 'http://comic.naver.com/webtoon/list.nhn'
    # GET parameters로 전달할 값들의 dict
    params = {'titleId': webtoon_id, 'page': page}
    return get_soup_from_url(url, params)


def get_webtoon_recent_episode_number(webtoon_id):
    '''
    웹툰의 첫 페이지, 첫 화 (가장 최신화)의 링크에서
    가장 최신화의 번호(=현재까지 연재한 횟수)를 가져온다
    :param webtoon_id: 웹툰 고유 ID
    :return: 최신 에피소드 번호(=총 연재횟수)
    '''
    soup = get_soup_from_naver_webtoon_by_page(webtoon_id)
    tr_list = soup.find_all('tr')
    recent_episode_number = None
    # 만화목록 페이지의 테이블에서 매 row를 순회하며
    for tr in tr_list:
        # class가 title인 td요소를 찾는다
        td = tr.find('td', class_='title')
        if td:
            # 링크주소가 있는 a요소
            a = td.find('a')
            # a요소의 href속성
            href = a.get('href')

            import re
            # 정규표현식, 아무문자열이나 반복되다가 ?no=또는 &no=이후의 숫자와 매칭된다
            p = re.compile(r'.*[?&]no=(\d+).*')
            m = re.match(p, href)
            # 링크주소에서 정규표현식의 패턴이 매치되었을 때
            if m:
                # 매치된 숫자를 recent_episode_number에 할당하고 반복문 종료
                recent_episode_number = m.group(1)
                break

    # HTML을 파싱한 결과는 문자열이므로 정수형으로 형변환 후 리턴
    return int(recent_episode_number)


def get_episode_list_from_page(webtoon_id, page=1):
    soup = get_soup_from_naver_webtoon_by_page(webtoon_id, page)
    # 리턴할 리스트
    episode_list = []

    # 첫 번째 tr요소는 기대하는 형태를 가지고 있지 않으므로 (td 4개를 포함하고 있지 않음) 제외
    tr_list = soup.find_all('tr')
    for index, tr in enumerate(tr_list):
        td_list = tr.find_all('td')
        # 각 row가 자식 td요소를 4개 미만으로 가지면 loop건너뜀
        if len(td_list) < 4:
            continue
        # 각 row가 몇 개의 td를 가지고 있는지 테스트
        # print('{} : {}'.format(index, len(td_list)))

        td_thumbnail = td_list[0]
        td_title = td_list[1]
        td_rating = td_list[2]
        td_created = td_list[3]

        title = td_title.get_text(strip=True)
        created = td_created.get_text(strip=True)
        link = td_title.find('a').get('href')

        cur_episode = {
            'title': title,
            'link': link,
            'created': created,
        }
        episode_list.append(cur_episode)
    return episode_list


def get_webtoon_episode_list(webtoon_id):
    '''
    특정 웹툰의 모든 에피소드 리스트를 리턴
    :param webtoon_id: 웹툰 고유 ID
    :return: 에피소드 dict의 list
    '''
    page_count = 10
    total_episode_list = []

    total_episode_number = get_webtoon_recent_episode_number(webtoon_id)
    import math

    # 총 페이지 수
    total_page_number = math.ceil(total_episode_number / page_count)

    # 각 페이지를 순회하며 리스트를 합침
    for i in range(total_page_number):
        cur_page_num = i + 1
        # 페이지번호의 HTML soup객체를 인자로 전달해서 episode dict list를 가져온다
        cur_episode_list = get_episode_list_from_page(webtoon_id, cur_page_num)
        # 현재 페이지에서 가져온 episode list를 total_episode_list리스트에 넣어준다
        total_episode_list.extend(cur_episode_list)

    # for episode in total_episode_list:
    #     print(episode)
    return total_episode_list
```